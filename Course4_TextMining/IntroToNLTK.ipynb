{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "_You are currently looking at **version 1.0** of this notebook. To download notebooks and datafiles, as well as get help on Jupyter notebooks in the Coursera platform, visit the [Jupyter Notebook FAQ](https://www.coursera.org/learn/python-text-mining/resources/d9pwm) course resource._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 - Introduction to NLTK\n",
    "\n",
    "In part 1 of this assignment you will use nltk to explore the Herman Melville novel Moby Dick. Then in part 2 you will create a spelling recommender function that uses nltk to find words similar to the misspelling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Analyzing Moby Dick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/maileivargas/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/maileivargas/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')  # only need to do once and never again? \n",
    "nltk.download('wordnet')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# If you would like to work with the raw text you can use 'moby_raw'\n",
    "with open('moby.txt', 'r') as f:\n",
    "    moby_raw = f.read()\n",
    "    \n",
    "# If you would like to work with the novel in nltk.Text format you can use 'text1'\n",
    "moby_tokens = nltk.word_tokenize(moby_raw)\n",
    "text1 = nltk.Text(moby_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[Moby Dick by Herman Melville 1851]\\n\\n\\nETYMOLOGY.\\n\\n(Supplied by a Late Consumptive Usher to a Grammar School)\\n\\nThe pale Usher--threadbare in coat, heart, body, and brain; I see him\\nnow.  He was ever dusting his old lexicons and grammars, with a queer\\nhandkerchief, mockingly embellished with all the gay flags of all the\\nknown nations of the world.  He loved to dust his old grammars; it\\nsomehow mildly reminded him of his mortality.\\n\\n\"While you take in hand to school others, and to teach them by wha'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moby_raw[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[',\n",
       " 'Moby',\n",
       " 'Dick',\n",
       " 'by',\n",
       " 'Herman',\n",
       " 'Melville',\n",
       " '1851',\n",
       " ']',\n",
       " 'ETYMOLOGY',\n",
       " '.',\n",
       " '(',\n",
       " 'Supplied',\n",
       " 'by',\n",
       " 'a',\n",
       " 'Late']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1\n",
    "\n",
    "How many tokens (words and punctuation symbols) are in text1?\n",
    "\n",
    "*This function should return an integer.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def example_one():\n",
    "    return len(nltk.word_tokenize(moby_raw)) # or alternatively len(text1)\n",
    "\n",
    "total_tokens = example_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254989"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "\n",
    "How many unique tokens (unique words and punctuation) does text1 have?\n",
    "\n",
    "*This function should return an integer.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def example_two():\n",
    "    return len(set(nltk.word_tokenize(moby_raw))) # or alternatively len(set(text1))\n",
    "\n",
    "unique_tokens = example_two()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20755"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3\n",
    "\n",
    "After lemmatizing the verbs, how many unique tokens does text1 have?\n",
    "\n",
    "*This function should return an integer.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 'a' - adjective\n",
    "# 'r' - adverb\n",
    "# 'n' - noun\n",
    "# 'v' - verb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "# nltk.download()\n",
    "\n",
    "def example_three():\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized = [lemmatizer.lemmatize(w,'v') for w in text1]\n",
    "    return set(lemmatized)\n",
    "\n",
    "verb_tokens = example_three()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'companionable',\n",
       " 'war-horse',\n",
       " 'Ganges',\n",
       " 'whit',\n",
       " 'vitiate',\n",
       " 'Kit',\n",
       " 'Chase',\n",
       " 'noblest',\n",
       " 'TALBOT',\n",
       " 'late',\n",
       " 'fundamental',\n",
       " 'pincers',\n",
       " 'pitch',\n",
       " 'Commanded',\n",
       " 'mine',\n",
       " 'rocky',\n",
       " 'terrific',\n",
       " 'dismissal',\n",
       " 'sashes',\n",
       " 'Harmattans',\n",
       " 'clan',\n",
       " 'Strong',\n",
       " 'encircle',\n",
       " 'REVENGE',\n",
       " 'adequately',\n",
       " 'hear',\n",
       " 'whetstone',\n",
       " 'deliriously',\n",
       " 'stampedoes',\n",
       " 'Forward',\n",
       " 'sea-monsters',\n",
       " 'worldly',\n",
       " 'civilly',\n",
       " 'mole',\n",
       " 'cheat',\n",
       " 'sticking-plaster',\n",
       " 'mainmast',\n",
       " 'whoop',\n",
       " 'incompatible',\n",
       " 'ventricles',\n",
       " 'taffrail',\n",
       " 'parenthesize',\n",
       " 'settlements',\n",
       " 'torpid',\n",
       " 'Mind',\n",
       " 'Want',\n",
       " 'colossal',\n",
       " 'Pippin',\n",
       " 'read',\n",
       " 'identify',\n",
       " 'ever-woven',\n",
       " 'nostril',\n",
       " 'lazily',\n",
       " 'flexion',\n",
       " 'prayers',\n",
       " 'upwards',\n",
       " 'fitfully',\n",
       " 'distinct',\n",
       " 'statistical',\n",
       " 'invitingly',\n",
       " 'wharves',\n",
       " 'loosen',\n",
       " 'ankers',\n",
       " 'U.',\n",
       " 'bakers',\n",
       " 'decease',\n",
       " 'dull',\n",
       " 'dusky',\n",
       " 'praise',\n",
       " '7',\n",
       " 'lowest',\n",
       " 'wolfish',\n",
       " 'Thirty',\n",
       " 'symbol',\n",
       " 'lower',\n",
       " 'scramble',\n",
       " 'obscurity',\n",
       " 'wakeful',\n",
       " 'skeleton',\n",
       " 'speedy',\n",
       " 'Fetch',\n",
       " 'Whereas',\n",
       " 'play-wearied',\n",
       " 'Will',\n",
       " 'comical',\n",
       " 'peaceable',\n",
       " 'Gently',\n",
       " 'Catskill',\n",
       " 'pall',\n",
       " 'principles',\n",
       " 'Clootz',\n",
       " 'unexhilarated',\n",
       " 'preternaturalness',\n",
       " 'supernaturalness',\n",
       " 'CAPTAINS',\n",
       " 'tragic',\n",
       " 'atrocious',\n",
       " 'deject',\n",
       " 'boom-like',\n",
       " 'entrench',\n",
       " 'reflection',\n",
       " 'pleat',\n",
       " 'MISSIONARY',\n",
       " 'Lifted',\n",
       " 'Cape-Town',\n",
       " 'bamboo',\n",
       " 'connexions',\n",
       " 'astir',\n",
       " 'L150',\n",
       " 'Barrens',\n",
       " 'susceptible',\n",
       " 'grass',\n",
       " 'Southern',\n",
       " 'strength',\n",
       " 'plaintiffs',\n",
       " 'capstans',\n",
       " '1729',\n",
       " 'islets',\n",
       " 'stage',\n",
       " 'contain',\n",
       " 'alluringly',\n",
       " 'WATCH',\n",
       " 'wag',\n",
       " 'Throw',\n",
       " 'appendage',\n",
       " 'sheath',\n",
       " 'death-forfeitures',\n",
       " 'Czar',\n",
       " 'sulkies',\n",
       " 'sceptre',\n",
       " 'pelvis',\n",
       " 'stirrings',\n",
       " 'faintly',\n",
       " 'unmanifested',\n",
       " 'Venetianly',\n",
       " 'blacken',\n",
       " 'Wellington',\n",
       " 'amidst',\n",
       " 'schooners',\n",
       " 'yea',\n",
       " 'nomenclature',\n",
       " 'edition',\n",
       " 'obstinate',\n",
       " 'Funeral',\n",
       " 'Morning',\n",
       " 'sullen',\n",
       " 'AZORE',\n",
       " 'refiningly',\n",
       " 'Koo-loo',\n",
       " 'liveliness',\n",
       " 'blubber-room',\n",
       " 'clearly',\n",
       " 'catacombs',\n",
       " 'perpetually',\n",
       " 'confluent',\n",
       " 'unquiet',\n",
       " 'benefit',\n",
       " 'skiff',\n",
       " 'spectre',\n",
       " 'sea-custom',\n",
       " 'hurl',\n",
       " 'lurch',\n",
       " 'natives',\n",
       " 'kitchen',\n",
       " 'adoration',\n",
       " 'Crown',\n",
       " 'part-pay',\n",
       " 'yield',\n",
       " 'brimful',\n",
       " 'reservation',\n",
       " 'ELLERY',\n",
       " 'douse',\n",
       " 'MANX',\n",
       " 'bressed',\n",
       " 'man-like',\n",
       " 'strictest',\n",
       " 'demigorgon',\n",
       " 'diameter',\n",
       " 'HVAL',\n",
       " 'stiver',\n",
       " 'trackless',\n",
       " 'CHAPTER',\n",
       " 'tidy',\n",
       " 'Scoresby',\n",
       " 'Floating',\n",
       " 'particular',\n",
       " 'gold-hunters',\n",
       " 'marbleize',\n",
       " 'favourite',\n",
       " 'glimpse',\n",
       " 'multitude',\n",
       " 'Wherefore',\n",
       " 'transcendental',\n",
       " 'underneath',\n",
       " 'wales',\n",
       " 'discreetly',\n",
       " 'seldom',\n",
       " 'vitality',\n",
       " 'redundant',\n",
       " 'head-foremost',\n",
       " 'Prince',\n",
       " 'seamless',\n",
       " 'deprecate',\n",
       " 'cabin-window',\n",
       " 'pick',\n",
       " 'salamed',\n",
       " 'loop',\n",
       " 'askance',\n",
       " 'hesitatingly',\n",
       " 'sword-fish',\n",
       " 'unfeatured',\n",
       " 'talisman',\n",
       " 'cottage',\n",
       " 'notoriety',\n",
       " 'cream',\n",
       " 'Know',\n",
       " 'STRING',\n",
       " 'fix',\n",
       " '105',\n",
       " 'examination',\n",
       " 'music',\n",
       " 'truly',\n",
       " 'invariability',\n",
       " 'exultingly',\n",
       " 'abortions',\n",
       " 'Fuego',\n",
       " 'violent',\n",
       " 'undecided',\n",
       " 'indefinitely',\n",
       " 'Learning',\n",
       " 'bosom',\n",
       " 'calculation',\n",
       " 'superior',\n",
       " 'honey',\n",
       " 'repentant',\n",
       " 'Mad',\n",
       " 'Cursed',\n",
       " 'most',\n",
       " \"July's\",\n",
       " 'cobweb',\n",
       " 'vividness',\n",
       " 'landsmen',\n",
       " 'maxim',\n",
       " 'Out',\n",
       " 'injustice',\n",
       " 'chess-man',\n",
       " 'insure',\n",
       " 'shrink',\n",
       " 'sentiment',\n",
       " 'victory',\n",
       " 'nightly',\n",
       " 'gay',\n",
       " 'dust',\n",
       " 'nearer',\n",
       " 'mischief',\n",
       " 'public',\n",
       " 'good-bye',\n",
       " 'intercept',\n",
       " 'Bunyan',\n",
       " 'priority',\n",
       " 'fountain',\n",
       " 'prospect',\n",
       " 'formally',\n",
       " '67',\n",
       " 'HERE',\n",
       " 'gentlemanlike',\n",
       " 'pore',\n",
       " 'ginger',\n",
       " 'baleen',\n",
       " 'long-togged',\n",
       " 'grain',\n",
       " 'incoherences',\n",
       " 'thunderbolts',\n",
       " 'automaton',\n",
       " 'history',\n",
       " 'Jupiter',\n",
       " 'Germain',\n",
       " 'Therein',\n",
       " 'holy',\n",
       " 'pleasantly',\n",
       " 'revenue',\n",
       " 'Accessory',\n",
       " 'insolent',\n",
       " 'Well',\n",
       " 'junk',\n",
       " 'buck',\n",
       " 'range',\n",
       " 'cloudless',\n",
       " 'whale-ground',\n",
       " 'five',\n",
       " 'bluish',\n",
       " 'November',\n",
       " 'berry',\n",
       " 'arise',\n",
       " 'soundest',\n",
       " 'growl',\n",
       " 'passionate',\n",
       " 'snug',\n",
       " 'whistle',\n",
       " 'filaments',\n",
       " '1778',\n",
       " 'broom',\n",
       " 'wouldst',\n",
       " 'ignite',\n",
       " 'OF',\n",
       " 'deliverer',\n",
       " 'Cognac',\n",
       " 'collectedness',\n",
       " 'maliciously',\n",
       " 'annually',\n",
       " 'stock-companies',\n",
       " 'milk-white',\n",
       " 'manufacture',\n",
       " 'incomputable',\n",
       " 'twenty-four',\n",
       " 'life-buoys',\n",
       " 'RICHARD',\n",
       " 'middle',\n",
       " 'episode',\n",
       " 'weekly',\n",
       " 'Physiognomically',\n",
       " 'Mat-Maker',\n",
       " 'heedful',\n",
       " 'anxiety',\n",
       " 'builder',\n",
       " 'Off',\n",
       " 'Lamp',\n",
       " 'full-grown',\n",
       " 'infatuate',\n",
       " 'scene',\n",
       " 'Yarman',\n",
       " 'muskets',\n",
       " 'bow-window',\n",
       " 'unwittingly',\n",
       " 'humorists',\n",
       " 'lubber',\n",
       " 'street-door',\n",
       " 'deaden',\n",
       " 'writhe',\n",
       " 'shady',\n",
       " '1ST',\n",
       " 'princes',\n",
       " 'entreaty',\n",
       " 'Hyena',\n",
       " 'Merrily',\n",
       " 'BERMUDAS',\n",
       " 'unostentatious',\n",
       " 'realize',\n",
       " 'devoutly',\n",
       " 'professor',\n",
       " 'trunks',\n",
       " 'movement',\n",
       " 'verily',\n",
       " 'decipher',\n",
       " 'mournful',\n",
       " 'apple-dumpling',\n",
       " \"'Adios\",\n",
       " 'pugnacious',\n",
       " 'render',\n",
       " 'good-hearted',\n",
       " 'Yet',\n",
       " 'heroically',\n",
       " 'mix',\n",
       " 'renounce',\n",
       " 'surpassingly',\n",
       " 'nomine',\n",
       " 'accompany',\n",
       " 'valleys',\n",
       " 'policy',\n",
       " 'mask',\n",
       " 'joyousness',\n",
       " 'twenty',\n",
       " 'anacondas',\n",
       " 'spiralizes',\n",
       " 'lumber-like',\n",
       " 'sphere',\n",
       " 'widow',\n",
       " 'reproachfully',\n",
       " 'AUGUST',\n",
       " 'organ-boys',\n",
       " 'imp',\n",
       " 'FISHERY',\n",
       " 'individuals',\n",
       " 'SLEEPY',\n",
       " 'inoffensive',\n",
       " 'demonstrations',\n",
       " 'et',\n",
       " 'measure',\n",
       " 'banquet',\n",
       " 'Post-Captain',\n",
       " 'formation',\n",
       " 'minutest',\n",
       " 'Hat',\n",
       " 'placelessly',\n",
       " 'small-pox',\n",
       " 'title-pages',\n",
       " 'lard',\n",
       " 'deep',\n",
       " 'lonely',\n",
       " 'waken',\n",
       " 'Pegu',\n",
       " 'Mistress',\n",
       " 'meanly',\n",
       " 'unthought',\n",
       " 'recluseness',\n",
       " 'starvation',\n",
       " 'Methuselah',\n",
       " 'primers',\n",
       " 'monopolise',\n",
       " 'fierceness',\n",
       " 'Reckon',\n",
       " 'efficient',\n",
       " 'Least',\n",
       " 'Potters',\n",
       " 'mightier',\n",
       " 'blood-muddled',\n",
       " 'tenderness',\n",
       " 'duel',\n",
       " 'half-hinting',\n",
       " 'ISOLATO',\n",
       " 'oil',\n",
       " 'strife',\n",
       " 'COILS',\n",
       " 'tasselled',\n",
       " 'dreadfully',\n",
       " 'queenly',\n",
       " 'Ordinaire',\n",
       " 'stories',\n",
       " 'tale',\n",
       " 'Bite',\n",
       " 'intermission',\n",
       " 'these',\n",
       " 'rueful',\n",
       " 'civility',\n",
       " 'violence',\n",
       " 'holiest',\n",
       " 'gull-like',\n",
       " 'Posted',\n",
       " 'halibut',\n",
       " 'purest',\n",
       " 'Elbe',\n",
       " 'salutation',\n",
       " 'crack',\n",
       " 'six',\n",
       " 'sly',\n",
       " 'resign',\n",
       " 'wring',\n",
       " 'vindicate',\n",
       " 'magnificence',\n",
       " 'relinquish',\n",
       " 'care-killing',\n",
       " 'YE',\n",
       " 'BROWN',\n",
       " 'pangs',\n",
       " 'Yea',\n",
       " 'oneself',\n",
       " 'imposingly',\n",
       " 'church',\n",
       " 'mist',\n",
       " 'emprise',\n",
       " 'Eight',\n",
       " 'J.',\n",
       " 'Try-works',\n",
       " 'steep',\n",
       " 'singularly',\n",
       " 'literature',\n",
       " 'fixedly',\n",
       " 'clayey',\n",
       " 'unstarched',\n",
       " 'Mesopotamian',\n",
       " 'cloud-shadows',\n",
       " 'by-play',\n",
       " 'Halting',\n",
       " 'candelabra-wise',\n",
       " 'ounce',\n",
       " '60,000',\n",
       " 'LEATHER',\n",
       " 'mend',\n",
       " 'Helena',\n",
       " 'havoc',\n",
       " 'Shore',\n",
       " \"we're\",\n",
       " 'inscription',\n",
       " 'observe',\n",
       " 'reckon',\n",
       " 'contraband',\n",
       " 'woraciousness',\n",
       " 'watch-coat',\n",
       " 'exactness',\n",
       " 'Gulf',\n",
       " 'trick',\n",
       " 'worship',\n",
       " 'high-flung',\n",
       " 'HISTORY',\n",
       " 'hair-breadth',\n",
       " 'ground-swell',\n",
       " 'waistband',\n",
       " 'Luff',\n",
       " 'suckle',\n",
       " 'circumstantial',\n",
       " 'fadest',\n",
       " 'easiest',\n",
       " 'recommend',\n",
       " 'peacefully',\n",
       " 'enviable',\n",
       " 'hammocks',\n",
       " 'Sphynx',\n",
       " 'assailants',\n",
       " 'pod',\n",
       " 'sufficit',\n",
       " 'whale-line',\n",
       " 'whetstones',\n",
       " 'mutilate',\n",
       " 'hindmost',\n",
       " 'sea-terms',\n",
       " 'collateral',\n",
       " 'Turkish-rugged',\n",
       " 'don',\n",
       " 'COMMODORE',\n",
       " 'tinkle',\n",
       " 'advertise',\n",
       " 'Dunkirk',\n",
       " 'Alone',\n",
       " 'my',\n",
       " 'grief',\n",
       " 'stun',\n",
       " '18',\n",
       " 'raven',\n",
       " 'Zoology',\n",
       " 'DIGNITY',\n",
       " 'icy',\n",
       " 'Canals',\n",
       " 'celebrity',\n",
       " 'whale-fleet',\n",
       " 'unctuousness',\n",
       " 'Medes',\n",
       " 'trip-hammers',\n",
       " 'south-eastward',\n",
       " 'incidental',\n",
       " 'cunning',\n",
       " 'brilliancy',\n",
       " 'SENTENCE',\n",
       " 'bucket',\n",
       " 'athletic',\n",
       " 'sentimentally',\n",
       " 'knobby',\n",
       " 'mizen-mast-head',\n",
       " 'charmingly',\n",
       " 'Rockaway',\n",
       " 'WAL',\n",
       " 'respirations',\n",
       " 'sixpence',\n",
       " 'habitual',\n",
       " 'Albino',\n",
       " 'slobgollion',\n",
       " 'triumphantly',\n",
       " 'insert',\n",
       " 'gamesome',\n",
       " 'an',\n",
       " 'merry-making',\n",
       " 'eternities',\n",
       " '129',\n",
       " 'club-hammer',\n",
       " 'porches',\n",
       " 'possess',\n",
       " 'river',\n",
       " 'forget',\n",
       " 'predecessor',\n",
       " 'classical',\n",
       " 'Mendanna',\n",
       " 'hydrants',\n",
       " 'roast',\n",
       " 'tiller',\n",
       " 'visitation',\n",
       " 'February',\n",
       " 'CREWS',\n",
       " 'thrive',\n",
       " 'Ray',\n",
       " 'OLD',\n",
       " 'HEARS',\n",
       " 'militant',\n",
       " 'straight',\n",
       " 'problems',\n",
       " 'LAMB',\n",
       " 'vat',\n",
       " 'movingly',\n",
       " 'meagre',\n",
       " 'tell-tale',\n",
       " 'Stab',\n",
       " 'scrub',\n",
       " 'fright',\n",
       " 'VERSION',\n",
       " 'sleepers',\n",
       " 'wastingly',\n",
       " 'spurn',\n",
       " 'Try-Works',\n",
       " 'Hittite',\n",
       " 'undiscernible',\n",
       " 'lade',\n",
       " 'Grampus',\n",
       " 'genteelly',\n",
       " '1821',\n",
       " 'bleakness',\n",
       " 'suburban',\n",
       " 'populous',\n",
       " 'vintages',\n",
       " 'Merchant',\n",
       " 'brutal',\n",
       " 'cartload',\n",
       " 'afford',\n",
       " 'hieroglyphical',\n",
       " 'death-lock',\n",
       " 'problem',\n",
       " 'puzzle',\n",
       " 'probable',\n",
       " 'nominally',\n",
       " 'nice',\n",
       " 'Franklin',\n",
       " 'Slave-ship',\n",
       " 'irresistibleness',\n",
       " 'undigested',\n",
       " 'Future',\n",
       " 'cramp',\n",
       " 'healthy',\n",
       " 'formerly',\n",
       " 'cheer',\n",
       " 'phrenological',\n",
       " 'disgust',\n",
       " 'vice',\n",
       " 'green-skulled',\n",
       " 'sofa',\n",
       " 'servants',\n",
       " 'Fain',\n",
       " 'blush',\n",
       " 'tragedy',\n",
       " 'swimmer',\n",
       " 'hereditarily',\n",
       " 'socially',\n",
       " 'That',\n",
       " 'EYES',\n",
       " 'Lion',\n",
       " 'allusions',\n",
       " 'Vedas',\n",
       " 'outrage',\n",
       " 'reliably',\n",
       " 'chance',\n",
       " 'broil',\n",
       " 'obtain',\n",
       " 'free-and-easy',\n",
       " 'Winds',\n",
       " 'housekeepers',\n",
       " 'interrogatively',\n",
       " 'corrupt',\n",
       " 'BLOWS',\n",
       " 'greybeards',\n",
       " 'foolishly',\n",
       " 'lift',\n",
       " 'bugbear',\n",
       " 'over-arboring',\n",
       " 'winter',\n",
       " 'Ahab',\n",
       " 'Season-on-the-Line',\n",
       " 'pout',\n",
       " \"How's\",\n",
       " 'Dragon',\n",
       " 'Sideways',\n",
       " 'generously',\n",
       " 'oil-can',\n",
       " 'seventh',\n",
       " 'Africa',\n",
       " 'pay',\n",
       " 'tremulous',\n",
       " 'dip',\n",
       " 'shade',\n",
       " 'clasp',\n",
       " 'somnambulisms',\n",
       " 'scarry',\n",
       " 'courage',\n",
       " 'drowsiness',\n",
       " 'fable-mongering',\n",
       " 'profounder',\n",
       " 'for',\n",
       " 'honourably',\n",
       " 'irresistibly',\n",
       " 'Malays',\n",
       " 'consciously',\n",
       " 'Smut',\n",
       " 'roundabout',\n",
       " 'with',\n",
       " 'domed',\n",
       " 'Hampshire',\n",
       " 'unmeaningly',\n",
       " 'caulk',\n",
       " 'helpless',\n",
       " 'capriciously',\n",
       " 'steaks',\n",
       " 'successively',\n",
       " 'pair',\n",
       " \"'But\",\n",
       " 'pitiable',\n",
       " 'Diminish',\n",
       " 'peasant',\n",
       " 'crape',\n",
       " 'demonstrable',\n",
       " '55',\n",
       " 'narrow-flowing',\n",
       " 'Copenhagen',\n",
       " 'controllable',\n",
       " 'Glancing',\n",
       " 'BATTLE',\n",
       " 'deadliness',\n",
       " 'deride',\n",
       " 'hunks',\n",
       " 'NEW',\n",
       " 'masoned',\n",
       " 'Good-humored',\n",
       " 'bunk',\n",
       " 'accomplishment',\n",
       " 'bigger',\n",
       " 'judgments',\n",
       " '550',\n",
       " 'downward',\n",
       " 'small-e',\n",
       " 'elate',\n",
       " 'albatrosses',\n",
       " 'Thine',\n",
       " 'ROSS',\n",
       " 'brain-battering',\n",
       " 'steamer',\n",
       " 'Catholic',\n",
       " 'signal',\n",
       " 'boughs',\n",
       " 'Typhoon',\n",
       " 'Quebec',\n",
       " 'inscriptions',\n",
       " 'rafter',\n",
       " 'waifed',\n",
       " 'pot-luck',\n",
       " 'leathern',\n",
       " 'Lit',\n",
       " 'attraction',\n",
       " 'cowards',\n",
       " 'Rhenish',\n",
       " 'whittle',\n",
       " 'lath',\n",
       " 'carpet-bag',\n",
       " 'rascal',\n",
       " 'universal',\n",
       " 'dent',\n",
       " 'wigwam',\n",
       " 'hie',\n",
       " 'periodicalness',\n",
       " 'Fanning',\n",
       " 'Pompey',\n",
       " 'peacefulness',\n",
       " 'brawn',\n",
       " 'warble',\n",
       " 'Honourary',\n",
       " 'La',\n",
       " 'smackingly',\n",
       " 'Shakers',\n",
       " 'trappers',\n",
       " 'exceptionable',\n",
       " '31st',\n",
       " 'connexion',\n",
       " 'Antarctic',\n",
       " 'mundane',\n",
       " 'prefigure',\n",
       " 'candy',\n",
       " 'insultest',\n",
       " 'fifth',\n",
       " 'diabolically',\n",
       " 'goods',\n",
       " 'Judge',\n",
       " 'cultivate',\n",
       " 'cymballed',\n",
       " 'SNEEZES',\n",
       " 'turkeys',\n",
       " 'sleeper',\n",
       " 'obstacle',\n",
       " 'Tun',\n",
       " 'HIM',\n",
       " 'boat-steerer',\n",
       " '99',\n",
       " \"Ahab's\",\n",
       " 'hardly',\n",
       " 'cart',\n",
       " 'England',\n",
       " 'head-beat',\n",
       " \"should'st\",\n",
       " 'award',\n",
       " 'fairer',\n",
       " 'HACKLUYT',\n",
       " 'whiskey',\n",
       " 'ST.',\n",
       " 'ordain',\n",
       " 'open-doored',\n",
       " 'Fat-Cutter',\n",
       " 'Tennessee',\n",
       " 'butter-boxes',\n",
       " 'graveyards',\n",
       " 'exclusive',\n",
       " 'conventional',\n",
       " 'fearless',\n",
       " 'Marius',\n",
       " \"e'en\",\n",
       " 'bravest',\n",
       " 'metropolis',\n",
       " 'savannas',\n",
       " 'remind',\n",
       " 'stronghold',\n",
       " 'ECUADOR',\n",
       " 'cardinals',\n",
       " 'boldly',\n",
       " '75',\n",
       " \"hand's\",\n",
       " 'busy',\n",
       " 'mouts',\n",
       " '19',\n",
       " 'fossil',\n",
       " 'abstract',\n",
       " 'Take',\n",
       " 'sorcery',\n",
       " 'unfavourable',\n",
       " 'quills',\n",
       " 'river-capitals',\n",
       " 'angrily',\n",
       " 'play',\n",
       " 'gravestone',\n",
       " 'furniture',\n",
       " 'bullets',\n",
       " 'precision',\n",
       " 'Bell',\n",
       " 'pall-bearers',\n",
       " 'Requiem',\n",
       " 'azure',\n",
       " 'four',\n",
       " 'lieutenant',\n",
       " 'starlight',\n",
       " 'shape',\n",
       " 'Bottom',\n",
       " 'himself',\n",
       " 'invunerable',\n",
       " 'silk',\n",
       " 'theoretic',\n",
       " \"'Then\",\n",
       " 'simple-witted',\n",
       " 'dearly',\n",
       " 'whale-cruisers',\n",
       " 'divulge',\n",
       " 'Ross',\n",
       " 'unfurnished',\n",
       " 'imperceptible',\n",
       " 'bridle-bitts',\n",
       " 'muzzle',\n",
       " 'holiday',\n",
       " 'tree-nails',\n",
       " 'drown',\n",
       " 'untraceable',\n",
       " 'rumble',\n",
       " 'request',\n",
       " 'Post',\n",
       " 'key-hole',\n",
       " 'acquiescence',\n",
       " 'jiffy',\n",
       " 'farrago',\n",
       " 'clamorous',\n",
       " 'inferences',\n",
       " 'gallied',\n",
       " 'intentions',\n",
       " 'bright',\n",
       " 'HERBERT',\n",
       " 'southerly',\n",
       " 'tobacco-smoke',\n",
       " 'Jackson',\n",
       " 'porch',\n",
       " \"housewives'\",\n",
       " 'waif-poles',\n",
       " 'fire-waters',\n",
       " 'AND',\n",
       " 'coincident',\n",
       " 'continuous',\n",
       " 'Narwhale',\n",
       " 'voluntary',\n",
       " 'bench',\n",
       " 'parchment',\n",
       " 'operation',\n",
       " 'wander',\n",
       " 'superb',\n",
       " 'manoeuvre',\n",
       " 'patron',\n",
       " 'upbraid',\n",
       " 'Praetorians',\n",
       " 'small',\n",
       " 'serene',\n",
       " 'yours',\n",
       " 'Sperm-whalemen',\n",
       " 'debtor',\n",
       " 'sail-needle',\n",
       " 'doxology',\n",
       " 'stratagem',\n",
       " 'Wood',\n",
       " 'attendance',\n",
       " 'nourish',\n",
       " 'fishing-ground',\n",
       " 'delivery',\n",
       " 'sea-taste',\n",
       " 'piers',\n",
       " 'monuments',\n",
       " 'semiweekly',\n",
       " 'collar',\n",
       " 'Witt',\n",
       " 'raze',\n",
       " 'burnish',\n",
       " 'Why',\n",
       " 'leaders',\n",
       " 'woof',\n",
       " 'improbable',\n",
       " 'vicissitude',\n",
       " 'burrower',\n",
       " 'skrimshander',\n",
       " 'lapse',\n",
       " 'thousand',\n",
       " 'low',\n",
       " 'aorta',\n",
       " '45',\n",
       " 'HAILS',\n",
       " 'comets',\n",
       " 'Better',\n",
       " 'origin',\n",
       " 'Coast',\n",
       " 'resemble',\n",
       " 'ignoramus',\n",
       " 'Make',\n",
       " 'unprofessional',\n",
       " \"Mungo's\",\n",
       " 'counterfeit',\n",
       " 'equality',\n",
       " 'three-year',\n",
       " 'ready',\n",
       " 'suppose',\n",
       " 'Daniel',\n",
       " 'Libra',\n",
       " 'appointments',\n",
       " 'clingest',\n",
       " 'noiselessly',\n",
       " 'specifically',\n",
       " 'vehemently',\n",
       " 'promotion',\n",
       " 'secrete',\n",
       " 'brushwood',\n",
       " 'Whitehall',\n",
       " 'brother-in-law',\n",
       " 'ring-bolt',\n",
       " 'shatter',\n",
       " 'bundle',\n",
       " 'V',\n",
       " 'awe',\n",
       " 'Povelson',\n",
       " 'aptitude',\n",
       " 'heaviest',\n",
       " 'gorgeous',\n",
       " 'SCORESBY',\n",
       " 'constantly',\n",
       " 'accident',\n",
       " 'consciences',\n",
       " 'learn',\n",
       " 'counterpane',\n",
       " 'ignominious',\n",
       " 'contemptuously',\n",
       " 'Olassen',\n",
       " 'Damocles',\n",
       " 'social',\n",
       " 'thunder',\n",
       " \"t'other\",\n",
       " 'entrap',\n",
       " 'enchantment',\n",
       " '100',\n",
       " 'Commonwealth',\n",
       " 'DO',\n",
       " 'scoot',\n",
       " 'June',\n",
       " 'insufficient',\n",
       " 'Those',\n",
       " 'juncture',\n",
       " 'sneak',\n",
       " 'a-whalin',\n",
       " 'insignificant',\n",
       " 'Conversation',\n",
       " 'age',\n",
       " 'concoct',\n",
       " 'marling-spike',\n",
       " 'Names',\n",
       " 'scare',\n",
       " 'layeth',\n",
       " 'vacancies',\n",
       " 'queen',\n",
       " 'seniors',\n",
       " 'crash',\n",
       " 'eight',\n",
       " ...}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verb_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "nltk.download()\n",
    "freq = FreqDist(text1)\n",
    "vocab = freq.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "What is the lexical diversity of the given text input? (i.e. ratio of unique tokens to the total number of tokens)\n",
    "\n",
    "*This function should return a float.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08139566804842562"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_one():\n",
    "    return unique_tokens / total_tokens\n",
    "\n",
    "answer_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "What percentage of tokens is 'whale'or 'Whale'?\n",
    "\n",
    "*This function should return a float.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4125668166077752"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_two(): \n",
    "    whale_amt = freq['whale'] + freq['Whale']\n",
    "    return whale_amt / total_tokens * 100\n",
    "\n",
    "answer_two()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "What are the 20 most frequently occurring (unique) tokens in the text? What is their frequency?\n",
    "\n",
    "*This function should return a list of 20 tuples where each tuple is of the form `(token, frequency)`. The list should be sorted in descending order of frequency.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', 19204),\n",
       " ('the', 13715),\n",
       " ('.', 7308),\n",
       " ('of', 6513),\n",
       " ('and', 6010),\n",
       " ('a', 4545),\n",
       " ('to', 4515),\n",
       " (';', 4173),\n",
       " ('in', 3908),\n",
       " ('that', 2978),\n",
       " ('his', 2459),\n",
       " ('it', 2196),\n",
       " ('I', 2097),\n",
       " ('!', 1767),\n",
       " ('is', 1722),\n",
       " ('--', 1713),\n",
       " ('with', 1659),\n",
       " ('he', 1658),\n",
       " ('was', 1639),\n",
       " ('as', 1620)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_three():\n",
    "    top20_freq_tokens = sorted([(a, b) for a, b in dict(freq).items()], key=lambda x:x[1], reverse =True)[:20]\n",
    "    return top20_freq_tokens\n",
    "\n",
    "answer_three()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "What tokens have a length of greater than 5 and frequency of more than 150?\n",
    "\n",
    "*This function should return a sorted list of the tokens that match the above constraints. To sort your list, use `sorted()`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Captain',\n",
       " 'Pequod',\n",
       " 'Queequeg',\n",
       " 'Starbuck',\n",
       " 'almost',\n",
       " 'before',\n",
       " 'himself',\n",
       " 'little',\n",
       " 'seemed',\n",
       " 'should',\n",
       " 'though',\n",
       " 'through',\n",
       " 'whales',\n",
       " 'without']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_four():\n",
    "    result = sorted([a for a in vocab if len(a) > 5 and freq[a] > 150])\n",
    "    return result\n",
    "\n",
    "answer_four()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "Find the longest word in text1 and that word's length.\n",
    "\n",
    "*This function should return a tuple `(longest_word, length)`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"twelve-o'clock-at-night\", 23)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_five():\n",
    "    longest_word = max([(x, len(x)) for x in vocab], key=lambda x:x[1])\n",
    "    return longest_word\n",
    "\n",
    "answer_five()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "What unique words have a frequency of more than 2000? What is their frequency?\n",
    "\n",
    "\"Hint:  you may want to use `isalpha()` to check if the token is a word and not punctuation.\"\n",
    "\n",
    "*This function should return a list of tuples of the form `(frequency, word)` sorted in descending order of frequency.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(13715, 'the'),\n",
       " (6513, 'of'),\n",
       " (6010, 'and'),\n",
       " (4545, 'a'),\n",
       " (4515, 'to'),\n",
       " (3908, 'in'),\n",
       " (2978, 'that'),\n",
       " (2459, 'his'),\n",
       " (2196, 'it'),\n",
       " (2097, 'I')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_six():\n",
    "    result_six = sorted([(freq[x], x) for x in vocab if x.isalpha() and freq[x] > 2000], reverse=True)\n",
    "    return result_six\n",
    "\n",
    "answer_six()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "What is the average number of tokens per sentence?\n",
    "\n",
    "*This function should return a float.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.881952902963864"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_seven():\n",
    "    sentence_word_count = []\n",
    "    sentences = nltk.sent_tokenize(moby_raw)\n",
    "    for sentence in sentences:\n",
    "        count = sentence_word_count.append(len(nltk.word_tokenize(sentence)))\n",
    "    avg_sentence_word_count = sum(sentence_word_count) / len(sentence_word_count)\n",
    "    return avg_sentence_word_count\n",
    "\n",
    "answer_seven()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "What are the 5 most frequent parts of speech in this text? What is their frequency?\n",
    "\n",
    "*This function should return a list of tuples of the form `(part_of_speech, frequency)` sorted in descending order of frequency.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/maileivargas/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('NN', 32730), ('IN', 28657), ('DT', 25867), (',', 19204), ('JJ', 17620)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "def answer_eight():\n",
    "    token_tags = nltk.pos_tag(text1)\n",
    "    tags = [x[1] for x in token_tags]\n",
    "    pos_distribution = FreqDist(tags)\n",
    "    pos = pos_distribution.keys()\n",
    "    pos_freq = sorted([(a, pos_distribution[a]) for a in pos], key=lambda x:x[1], reverse=True)\n",
    "    return pos_freq[:5]\n",
    "\n",
    "answer_eight()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Spelling Recommender\n",
    "\n",
    "For this part of the assignment you will create three different spelling recommenders, that each take a list of misspelled words and recommends a correctly spelled word for every word in the list.\n",
    "\n",
    "For every misspelled word, the recommender should find find the word in `correct_spellings` that has the shortest distance*, and starts with the same letter as the misspelled word, and return that word as a recommendation.\n",
    "\n",
    "*Each of the three different recommenders will use a different distance measure (outlined below).\n",
    "\n",
    "Each of the recommenders should provide recommendations for the three default words provided: `['cormulent', 'incendenece', 'validrate']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/maileivargas/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/words.zip.\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import words\n",
    "nltk.download('words')\n",
    "\n",
    "correct_spellings = words.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "236736"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(correct_spellings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "\n",
    "For this recommender, your function should provide recommendations for the three default words provided above using the following distance metric:\n",
    "\n",
    "**[Jaccard distance](https://en.wikipedia.org/wiki/Jaccard_index) on the trigrams of the two words.**\n",
    "\n",
    "*This function should return a list of length three:\n",
    "`['cormulent_reccomendation', 'incendenece_reccomendation', 'validrate_reccomendation']`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['corpulent', 'indecence', 'validate']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_nine(entries=['cormulent', 'incendenece', 'validrate']):\n",
    "    reccomendation = []\n",
    "    for given_word in entries:\n",
    "        Jac_coeff = []\n",
    "        for word in correct_spellings:\n",
    "            if given_word[0] == word[0]:\n",
    "                # find the trigrams for each word and given word\n",
    "                a = set([given_word[i:i+3] for i in range(0, len(given_word) - 2)])  # given_word_trigrams\n",
    "                b = set([word[i:i+3] for i in range(0, len(word) - 2)])              # word_trigrams\n",
    "                \n",
    "                intersection = len(list(a & b))        # find the length of the intersection of trigrams\n",
    "                union = len(list(a | b))               # find the length of the union of trigrams\n",
    "                Jaccard_dist = intersection / union    # Jaccard dictance coefficient\n",
    "                Jac_coeff.append((Jaccard_dist, word)) # put the possible matching word and its coefficient in a list\n",
    "                \n",
    "        best = max(Jac_coeff)                          # find the highest coefficient\n",
    "        reccomendation.append(best[1])                 # extract the word with the best coefficient \n",
    "    return reccomendation\n",
    "    \n",
    "answer_nine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "\n",
    "For this recommender, your function should provide recommendations for the three default words provided above using the following distance metric:\n",
    "\n",
    "**[Jaccard distance](https://en.wikipedia.org/wiki/Jaccard_index) on the 4-grams of the two words.**\n",
    "\n",
    "*This function should return a list of length three:\n",
    "`['cormulent_reccomendation', 'incendenece_reccomendation', 'validrate_reccomendation']`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cormus', 'incendiary', 'valid']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_ten(entries=['cormulent', 'incendenece', 'validrate']):\n",
    "    reccomendation = []\n",
    "    for given_word in entries:\n",
    "        Jac_coeff = []\n",
    "        for word in correct_spellings:\n",
    "            if given_word[0] == word[0]:\n",
    "                # find the trigrams for each word and given word\n",
    "                a = set([given_word[i:i+4] for i in range(0, len(given_word) - 3)])  # given_word_4grams\n",
    "                b = set([word[i:i+4] for i in range(0, len(word) - 3)])              # word_4grams\n",
    "                \n",
    "                intersection = len(list(a & b))        # find the length of the intersection of trigrams\n",
    "                union = len(list(a | b))               # find the length of the union of 4grams\n",
    "                Jaccard_dist = intersection / union    # Jaccard dictance coefficient\n",
    "                Jac_coeff.append((Jaccard_dist, word)) # put the possible matching word and its coefficient in a list\n",
    "                \n",
    "        best = max(Jac_coeff)                          # find the highest coefficient\n",
    "        reccomendation.append(best[1])                 # extract the word with the best coefficient \n",
    "    return reccomendation\n",
    "    \n",
    "answer_ten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 11\n",
    "\n",
    "For this recommender, your function should provide recommendations for the three default words provided above using the following distance metric:\n",
    "\n",
    "**[Edit distance on the two words with transpositions.](https://en.wikipedia.org/wiki/Damerau%E2%80%93Levenshtein_distance)**\n",
    "\n",
    "*This function should return a list of length three:\n",
    "`['cormulent_reccomendation', 'incendenece_reccomendation', 'validrate_reccomendation']`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['corpulent', 'intendence', 'validate']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def answer_eleven(entries=['cormulent', 'incendenece', 'validrate']):\n",
    "    \n",
    "    # from https://en.wikibooks.org/wiki/Algorithm_Implementation/Strings/Levenshtein_distance\n",
    "    # Christopher P. Matthews\n",
    "    # christophermatthews1985@gmail.com\n",
    "    \n",
    "    def levenshtein(s, t):\n",
    "        ''' From Wikipedia article; Iterative with two matrix rows. '''\n",
    "        if s == t: return 0\n",
    "        elif len(s) == 0: return len(t)\n",
    "        elif len(t) == 0: return len(s)\n",
    "        v0 = [None] * (len(t) + 1)\n",
    "        v1 = [None] * (len(t) + 1)\n",
    "        for i in range(len(v0)):\n",
    "            v0[i] = i\n",
    "        for i in range(len(s)):\n",
    "            v1[0] = i + 1\n",
    "            for j in range(len(t)):\n",
    "                cost = 0 if s[i] == t[j] else 1\n",
    "                v1[j + 1] = min(v1[j] + 1, v0[j + 1] + 1, v0[j] + cost)\n",
    "            for j in range(len(v0)):\n",
    "                v0[j] = v1[j]\n",
    "                \n",
    "        return v1[len(t)]\n",
    "    \n",
    "    # iterate through the list of the given words and the correct spelled words\n",
    "    reccomendation = []\n",
    "    for given_word in entries:\n",
    "        levenshtein_score = []\n",
    "        for word in correct_spellings:\n",
    "            if given_word[0] == word[0]:    # verify that they word start with the same letter\n",
    "                levenshtein_score.append((levenshtein(given_word, word), word))  # append the scores to a list\n",
    "        \n",
    "        best = min(levenshtein_score)      # find the best score, or the lowest score in this case\n",
    "        reccomendation.append(best[1])     # extract the word associated with the \"best\" score\n",
    "    \n",
    "    return reccomendation\n",
    "    \n",
    "answer_eleven()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-text-mining",
   "graded_item_id": "r35En",
   "launcher_item_id": "tCVfW",
   "part_id": "NTVgL"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
